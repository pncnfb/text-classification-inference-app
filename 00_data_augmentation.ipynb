{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NumXBGRjEcGs"
      },
      "source": [
        "# 00 Data Augmentation\n",
        "In this notebook, I perform data augmentation using a Large Language Model (LLM). The goal is to generate new documents by modifying the original ones, ensuring that the data is augmented while preserving textual diversity and maintaining the core meaning.\n",
        "\n",
        "### Notes\n",
        "I reviewed the standard approaches for textual data augmentation in the literature. However, given my knowledge of the Generative AI field, I preferred to delegate the creation of new samples to an LLM (in this case, Gemini). This is because I believe that, when used correctly, these models can potentially outperform traditional data augmentation technique (especially for textual data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPo69365Edeh"
      },
      "source": [
        "## 0 | Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0.1 | Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install pydantic==2.8.2 -q\n",
        "!pip3 install google-cloud-aiplatform==1.62.0 -q\n",
        "!pip3 install llama-index-llms-gemini==0.3.1 -q\n",
        "!pip3 install llama-index==0.11.0 -q\n",
        "!pip3 install llama-index-llms-vertex==0.3.2 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0.2 | Google Cloud Login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!gcloud auth login\n",
        "!gcloud auth application-default login\n",
        "!gcloud config set project <your-project-id>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0.3 | Declare Environment variables \n",
        "In this section, we define and initialize the environment variables required for the notebook. These variables typically include project configurations, model parameters, and other settings necessary to run the data augmentation process. Declaring them ensures a consistent and flexible environment for executing the subsequent steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['PROJECT_ID'] = '<your-project-id>'\n",
        "os.environ['REGION'] = 'europe-west4'\n",
        "os.environ['MODEL'] = 'gemini-2.0-flash' # I used flash for a speed up\n",
        "os.environ['TEMPERATURE'] = '1'\n",
        "os.environ['MAX_RETRIES'] = '5'\n",
        "os.environ['MAX_TOKENS'] = '8192'\n",
        "os.environ['PROMPT_TEMPLATE'] = \"\"\"\n",
        "# Goal\n",
        "\n",
        "I will input a medical document belonging to a specific category (orthopaedics, radiology, gastroenterology, neurology, urology).\n",
        "\n",
        "The objective is to perform data augmentation, i.e. to generate a new document inspired by the original but sufficiently distinct, while maintaining consistency with the reference medical category.\n",
        "Use technique like this:\n",
        "    - random deletion,\n",
        "    - random insertion,\n",
        "    - shuffling,\n",
        "    - synonym replacement\n",
        "\n",
        "#Important\n",
        "\n",
        "- A machine learning algorithm must not understand interpreting the generated document as different from the first one\n",
        "- Never put special characters like \\\\u0000-\\\\u001F or others\n",
        "\n",
        "# Parameters\n",
        "\n",
        "Consider these parameters during the generation of the response:\n",
        "\n",
        "    - <category>: The category label of the document\n",
        "    - <original_document>: The input text document that needs augmentation\n",
        "\n",
        "<category>\n",
        "{category}\n",
        "</category>\n",
        "\n",
        "<original_document>\n",
        "{original_document}\n",
        "</original_document>\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0.3 | Output Model Definition\n",
        "Pydantic models are used to structure and validate the output data from the model, ensuring that it adheres to the expected format. By defining the model, we ensure that the generated text is properly encapsulated, with clear specifications for attributes such as the augmented text and other metadata.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class ResponseAI(BaseModel):\n",
        "    text: str = Field(\n",
        "        description=\"The new document\", examples=[\"Lorem ipsum \"]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0.4 | Agent Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This class helps me keep the code organized and have a reusable component in other notebooks or various applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "from vertexai.generative_models._generative_models import HarmBlockThreshold, HarmCategory\n",
        "from llama_index.core import PromptTemplate\n",
        "from llama_index.core.output_parsers import PydanticOutputParser\n",
        "from llama_index.core.program import LLMTextCompletionProgram\n",
        "from llama_index.llms.vertex import Vertex\n",
        "\n",
        "class VertexAIAgent:\n",
        "    def __init__(self, project_id, region, model_name, temperature, max_retries, max_tokens, prompt_template, safety_settings=None):\n",
        "        \"\"\"\n",
        "        Initialize the Vertex AI Model for text generation.\n",
        "\n",
        "        :param project_id: Google Cloud project ID\n",
        "        :param region: Google Cloud region\n",
        "        :param model_name: Name of the model to use\n",
        "        :param temperature: Temperature setting for randomness\n",
        "        :param max_retries: Max retries for requests\n",
        "        :param max_tokens: Max tokens for the response\n",
        "        :param prompt_template: The prompt template to use for generating text\n",
        "        :param safety_settings: (optional) Custom safety settings for content filtering\n",
        "        \"\"\"\n",
        "        self.project_id = project_id\n",
        "        self.region = region\n",
        "        self.model_name = model_name\n",
        "        self.temperature = temperature\n",
        "        self.max_retries = max_retries\n",
        "        self.max_tokens = max_tokens\n",
        "        self.prompt_template = prompt_template\n",
        "\n",
        "        aiplatform.init(project=self.project_id, location=self.region)\n",
        "\n",
        "        if safety_settings is None:\n",
        "            safety_settings = {\n",
        "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
        "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "                HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
        "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
        "            }\n",
        "\n",
        "        self.llm = Vertex(\n",
        "            model=self.model_name,\n",
        "            temperature=self.temperature,\n",
        "            max_retries=self.max_retries,\n",
        "            max_tokens=self.max_tokens,\n",
        "            safety_settings=safety_settings,\n",
        "        )\n",
        "\n",
        "        self.parser = PydanticOutputParser(output_cls=ResponseAI)\n",
        "\n",
        "        self.prompt_template = PromptTemplate(template=self.prompt_template)\n",
        "\n",
        "        self.llm_assistant = LLMTextCompletionProgram.from_defaults(\n",
        "            output_cls=ResponseAI,\n",
        "            output_parser=self.parser,\n",
        "            prompt=self.prompt_template,\n",
        "            llm=self.llm,\n",
        "            verbose=True,\n",
        "            #response_validation=False\n",
        "        )\n",
        "\n",
        "    def generate_text(self, original_document, category):#, augmentation_type):\n",
        "        \"\"\"\n",
        "        Generate augmented text from the original document based on the given category and augmentation type.\n",
        "\n",
        "        :param original_document: The original document text to augment\n",
        "        :param category: The category label of the document\n",
        "        :param augmentation_type: The type of augmentation to perform (e.g., \"paraphrasing\", \"summarization\")\n",
        "        :return: The augmented text generated by the model\n",
        "        \"\"\"\n",
        "        output = self.llm_assistant(\n",
        "            original_document=original_document,\n",
        "            category=category,\n",
        "            #augmentation_type=augmentation_type\n",
        "        )\n",
        "        return output.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1 | Train Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.1 | Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv(\"./train/train_data.csv\")\n",
        "label_counts = train_data['domain'].value_counts()\n",
        "\n",
        "print(\"Label Distribution:\\n\", label_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2 | Minority Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Determine the minority class threshold (e.g., below mean count)\n",
        "minority_classes = label_counts[label_counts < label_counts.max()].index.tolist()\n",
        "\n",
        "print(\"Minority Classes:\", minority_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2 | Augment Data\n",
        "In this section, gemini is used to generate new documents from the originals. The output is checked with Pydantic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.1 | Initialize LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_llm = VertexAIAgent(\n",
        "        project_id=os.environ['PROJECT_ID'],\n",
        "        region=os.environ['REGION'],\n",
        "        model_name=os.environ['MODEL'],\n",
        "        temperature=os.environ['TEMPERATURE'],\n",
        "        max_retries=os.environ['MAX_RETRIES'],\n",
        "        max_tokens=os.environ['MAX_TOKENS'],\n",
        "        prompt_template=os.environ['PROMPT_TEMPLATE']\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2 | Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Removes control characters and unwanted whitespace from the text.\"\"\"\n",
        "    text = re.sub(r'[\\x00-\\x1F\\x7F]', '', text)  # Remove control characters\n",
        "    text = text.replace(\"\\ufeff\", \"\")  # Remove BOM characters if present\n",
        "    text = text.strip()  # Trim whitespace\n",
        "    return text\n",
        "\n",
        "\n",
        "def save_augmented_document(augmented_text:str, category:str, file_name:str, out_folder:str):\n",
        "    \"\"\"\n",
        "    Save the augmented version of the document to the specified folder.\n",
        "\n",
        "    :param augmented_text: The generated augmented text.\n",
        "    :param category: The category of the document (used for naming and organization).\n",
        "    :param file_name: The original file name, used to create the augmented file name.\n",
        "    :param augmented_folder: The folder path where the augmented document will be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    augmented_file_path = os.path.join(out_folder, f\"aug_{category}_{file_name}\")\n",
        "\n",
        "    with open(augmented_file_path, \"w\", encoding=\"utf-8\") as aug_file:\n",
        "        aug_file.write(augmented_text)\n",
        "\n",
        "    print(f\"Augmented document `{file_name}` saved to `{augmented_file_path}`\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.3 | Generate and Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "out_folder = \"./train/augment\"\n",
        "os.makedirs(out_folder, exist_ok=True)\n",
        "\n",
        "for category in [\"Neurology\", \"Orthopedic\", \"Urology\", \"Radiology\",\"Gastroenterology\"]:\n",
        "\n",
        "    category_files = train_data[train_data['domain'] == category]['file_name'].tolist()\n",
        "\n",
        "    for file_name in category_files:\n",
        "        file_path = f\"./train/notes/{file_name}\"\n",
        "\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "                original_text = file.read()\n",
        "        except UnicodeDecodeError:\n",
        "            with open(file_path, \"r\", encoding=\"latin1\") as file:\n",
        "                original_text = file.read()\n",
        "\n",
        "        out_document = _llm.generate_text(\n",
        "            original_document=clean_text(original_text),\n",
        "            category=category\n",
        "        )\n",
        "\n",
        "        save_augmented_document(augmented_text=out_document,\n",
        "                                category=category,\n",
        "                                file_name=file_name,\n",
        "                                out_folder=out_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.4 | Save additional Training Data\n",
        "Saves .csv file with (file_name, domain) header"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import re\n",
        "\n",
        "def extract_domain_and_filename(file_name:str)->tuple[str, str]:\n",
        "    \"\"\"Extracts the domain from the filename while keeping the full filename.\"\"\"\n",
        "    match = re.match(r'aug_([A-Za-z]+)_\\d+\\.txt', file_name)\n",
        "    if match:\n",
        "        domain = match.group(1)\n",
        "        return file_name, domain\n",
        "    return file_name, \"Unknown\"\n",
        "\n",
        "def generate_csv(folder_path:str, output_file:str):\n",
        "    \"\"\"Generates a CSV file with file names and domains.\"\"\"\n",
        "    file_entries = []\n",
        "\n",
        "    for file_name in sorted(os.listdir(folder_path)):\n",
        "        if file_name.endswith(\".txt\"):\n",
        "            full_file_name, domain = extract_domain_and_filename(file_name)\n",
        "            file_entries.append([full_file_name, domain])\n",
        "\n",
        "    with open(output_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"file_name\", \"domain\"])\n",
        "        writer.writerows(file_entries)\n",
        "\n",
        "    print(f\"CSV file '{output_file}' created successfully.\")\n",
        "\n",
        "generate_csv(folder_path=\"./train/augment/\",output_file=\"./train/train_data_aug.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Considerations\n",
        "\n",
        "This data augmentation approach enables the generation of new documents with enough variations to maintain diversity, ensuring that our machine learning algorithms recognize them as distinct.\n",
        "For example, you may notice that parameters such as age, vitals and other details change slightly, allowing us to consider the new document as new samples."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
